import sys
import io
import requests
import json
import os
from datetime import datetime, timedelta

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")

def fetch_bulk_data():
    base_url = "https://doublexp.net/static/json/bulkmissions/"
    # ì–´ì œ, ì˜¤ëŠ˜, ë‚´ì¼ ë°ì´í„°ë¥¼ ëª¨ë‘ ê°€ì ¸ì™€ì„œ ê°€ìš©ì„± í™•ë³´
    dates = [(datetime.utcnow() + timedelta(days=i)).strftime('%Y-%m-%d') for i in range(-1, 2)]
    optimized_data = {}

    for date in dates:
        url = f"{base_url}{date}.json"
        print(f"Fetching {url}...")
        try:
            res = requests.get(url, timeout=15)
            if res.status_code == 200:
                raw = res.json()
                for ts, content in raw.items():
                    # 1. ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹Œ í‚¤(ver, dailyDeal ë“±) ì œì™¸
                    if not isinstance(content, dict):
                        continue
                    
                    missions_list = []
                    biomes = content.get("Biomes", {})
                    for biome_name, missions in biomes.items():
                        for m in missions:
                            # 2. ë°ì´í„° êµ¬ì¡° ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
                            # MissionMutator: Double XP, Low Gravity ë“± (í•˜ë‚˜ì˜ ë¬¸ìì—´)
                            # MissionWarnings: Swarmageddon ë“± (ë¦¬ìŠ¤íŠ¸ í˜•íƒœ)
                            mutator = m.get("MissionMutator")
                            warnings = m.get("MissionWarnings", [])
                            
                            missions_list.append({
                                "b": biome_name,
                                "t": m.get("PrimaryObjective"),
                                "so": m.get("SecondaryObjective"),
                                "cn": m.get("CodeName"),
                                "l": int(m.get("Length", 1)),
                                "c": int(m.get("Complexity", 1)),
                                "bf": mutator if mutator else None,
                                "df": ", ".join(warnings) if warnings else None,
                                "s": m.get("included_in", [])
                            })
                    optimized_data[ts] = missions_list
            else:
                print(f"Failed to fetch {date}: Status {res.status_code}")
        except Exception as e:
            print(f"Error processing {date}: {e}")

    if optimized_data:
        # __file__ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ â†’ ë¡œì»¬Â·GitHub Actions ëª¨ë‘ ì˜¬ë°”ë¥´ê²Œ ë™ì‘
        script_dir = os.path.dirname(os.path.abspath(__file__))
        out_path = os.path.join(script_dir, '..', 'data', 'daily_missions.json')
        out_path = os.path.normpath(out_path)
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        with open(out_path, 'w', encoding='utf-8') as f:
            json.dump(optimized_data, f, ensure_ascii=False)
        print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {out_path}")
        print(f"âœ… ìµœì í™” ì™„ë£Œ: {len(optimized_data)} ê°œì˜ íƒ€ì„ìŠ¬ë¡¯ ì €ì¥ë¨")
        
        # ê²€ì¦ ì¶œë ¥
        has_double_xp = any(m['bf'] == "Double XP" for ms in optimized_data.values() for m in ms)
        print(f"ğŸ” Double XP ë°ì´í„° í¬í•¨ ì—¬ë¶€: {has_double_xp}")

if __name__ == "__main__":
    fetch_bulk_data()
